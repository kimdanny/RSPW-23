{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/aldolipani/SDAE22/blob/master/SDAE_DL_Tutorial_on_Lucas_et_al.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Day 3 - Geospatial Engineering\n",
    "## Predicting Electrical Conductivity with Deep Learning\n",
    "\n",
    "### Aim\n",
    "In this tutorial we will see how to solve this task using tabular data, raster data, and their combination.\n",
    "\n",
    "\n",
    "### Acknowledgement\n",
    "This notebook is written by [Dr. Aldo Lipani](aldolipani.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oyJ4GpF4Cn1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb3JZ9gO4Cn1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! pip install rasterio livelossplot torchviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0u5kXJh4Cn2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And import all we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObLXcxCe4Cn2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "from matplotlib import pyplot as plot\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchviz import make_dot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq-PsXYH4Cn2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the Tabular Dataset\n",
    "\n",
    "Let's load the dataset and remove any Not a Numbers (NAs) it may contain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQgec2lJ4Cn2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/aldolipani/SDAE22/master/data/logEC_2015_wgs_soil_cov.csv', index_col=0)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbtUvvq44Cn2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Number of samples: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9djEeF-4Cn3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To make the training quick, we decided to select only those points that lie within the Sicilian region (Italy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4UVj3ql4Cn3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# bounding box of Sicily in WGS\n",
    "bbox_sicily = {'xwgs_0': 12.221645,\n",
    "               'xwgs_1': 15.682920,\n",
    "               'ywgs_0': 36.304816,\n",
    "               'ywgs_1': 38.582695}\n",
    "\n",
    "df_sicily = df[(df['xwgs'] >= bbox_sicily['xwgs_0']) & (df['ywgs'] >= bbox_sicily['ywgs_0']) &\n",
    "               (df['xwgs'] <= bbox_sicily['xwgs_1']) & (df['ywgs'] <= bbox_sicily['ywgs_1'])]\n",
    "\n",
    "df_sicily.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGImlgVs4Cn3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of samples in Sicily:', len(df_sicily))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2Q1rznS4Cn3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Normalization\n",
    "\n",
    "This dataset contains only continues variables. This means that we do not need to encode any categorical variables. To normalize each values we can use a Min Max normalization from the scikit-learn packages. Please note that we do the same also for the target variable. For neural networks, it is always recomended to have attributes with values that range within -3 to 3. This in order to avoid exploding gradient issues while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLAnZ8114Cn3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we make a copy of all rows\n",
    "all_rows = df_sicily.copy()\n",
    "\n",
    "# we copy and transform the target attribute\n",
    "ys = np.array(all_rows['y']).reshape((-1, 1))\n",
    "min_max_scaler_ys = MinMaxScaler()\n",
    "ys = min_max_scaler_ys.fit_transform(ys)\n",
    "ys = ys.reshape(-1)\n",
    "\n",
    "# we delete the target attributes from all_rows\n",
    "del all_rows['y']\n",
    "del all_rows['xwgs']\n",
    "del all_rows['ywgs']\n",
    "\n",
    "# we transform the samples\n",
    "min_max_scaler_xs = MinMaxScaler()\n",
    "all_rows = min_max_scaler_xs.fit_transform(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fGkvl624Cn4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tabular dataset is now ready.\n",
    "\n",
    "## Load the Raster Dataset\n",
    "\n",
    "In this tutorial we will try to combine NDVI rasters to the tabular data above. These rasters are about Sicily. In order to use the rasters, we first need to download them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OG3-L7cO4Cn4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/aldolipani/SDAE22.git\n",
    "! mkdir data\n",
    "! mv SDAE22/data/rasters ./data/rasters\n",
    "! rm -fr SDAE22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN49hhdn4Cn4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now load the rasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAC27cdJ4Cn5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rasters = {}\n",
    "\n",
    "for file in tqdm(glob('data/rasters/*.tif')):\n",
    "    feature = file.split('/')[-1][:-4]\n",
    "    rasters[feature] = rasterio.open(file)\n",
    "\n",
    "print('Raster features:', list(rasters.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp8b98W54Cn5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's have a look if the NDVI 7 raster looks like Sicily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdcPt0WS4Cn5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot.imshow(rasters['NDVI_M7_02'].read(1), vmin=-1, vmax=1, cmap='pink')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Anw4u3cS4Cn5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now have a look at the empirical distribution of values of this raster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Qrh9B-y4Cn5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot.hist(rasters['NDVI_M7_02'].read(1).reshape((-1,)), bins=50)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STq2O8JJ4Cn5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "NDVI is $\\in [0, 1]$. However, we can observe that there other values at 255. These values represent missing NDVI values due to sea or clouds. We will replace these values with -1s. We now visualize the empiricial distribution around the normal range of NDVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nxEGSMj4Cn5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot.hist(rasters['NDVI_M7_02'].read(1).reshape((-1,)), range=(-1, 1), bins=50)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itjnBrvK4Cn6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot.hist(rasters['NDVI_M7_02'].read(1).reshape((-1,)), range=(250, 256), bins=50)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu8OY4qK4Cn6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now clip squares around the tabular dataset points of size 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3Pznlu54Cn6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "half_window_size = 5 # change this number of if you want to have larger windows\n",
    "# this list will contain all images\n",
    "all_images = []\n",
    "for index, row in tqdm(df_sicily.iterrows()):\n",
    "    all_images.append({})\n",
    "    for raster in rasters:\n",
    "        x, y = rasters[raster].index(row['xwgs'], row['ywgs'])\n",
    "        clip = rasters[raster].read(1)[x - half_window_size:x + half_window_size + 1, y - half_window_size + 1:y + half_window_size + 2]\n",
    "        all_images[-1][raster] = np.array(clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8ldCGNU4Cn6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIyMwfU44Cn6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The raster dataset is now ready.\n",
    "\n",
    "# Train, Validation, Test Splits\n",
    "\n",
    "We will perform a 8:1:1 train, validation and test splits. This will be done applying the `train_test_split` of scikit-lean twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE2-boWB4Cn6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows_train, rows_test, images_train, images_test, ys_train, ys_test = train_test_split(all_rows, all_images, ys,\n",
    "                                                                                       test_size=0.1, random_state=42)\n",
    "\n",
    "rows_train, rows_val, images_train, images_val, ys_train, ys_val = train_test_split(rows_train, images_train, ys_train,\n",
    "                                                                                    test_size=0.111111, random_state=42)\n",
    "\n",
    "print(f'training set size: {len(rows_train)}, validation set size: {len(rows_val)}, testing set size: {len(rows_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MWmq9sm4Cn6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now define a helper class to use the dataset. This class will take as input the tabular data (`all_rows`), the raster data (`all_images`) and labels (`ys`) and help us iterate over the dataset in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3SjD0Bo4Cn7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RowImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, all_rows, all_images, ys):\n",
    "        self.all_rows = all_rows\n",
    "        self.all_images = all_images\n",
    "        self.ys = ys\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        row = torch.tensor(self.all_rows[idx])\n",
    "        images = self.all_images[idx]\n",
    "        image = torch.stack([torch.from_numpy(images[k]) for k in sorted(images.keys())], dim=0).double()\n",
    "        y = torch.tensor(self.ys[idx]).reshape((-1,))\n",
    "\n",
    "        sample = {'row': row, 'image': image, 'y': y}\n",
    "        return sample\n",
    "\n",
    "# we initialize this dataset for the training set\n",
    "dataset_train = RowImageDataset(rows_train,\n",
    "                                images_train,\n",
    "                                ys_train)\n",
    "\n",
    "# the validation set\n",
    "dataset_val = RowImageDataset(rows_val,\n",
    "                              images_val,\n",
    "                              ys_val)\n",
    "\n",
    "# and the test set\n",
    "dataset_test = RowImageDataset(rows_test,\n",
    "                               images_test,\n",
    "                               ys_test)\n",
    "\n",
    "# we now output the first training example\n",
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs0QPGZR4Cn7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deep Learning Architectures\n",
    "\n",
    "We will explore the predictive power of 3 deep learning architectures: one architecture for tabular data, one for raster data and one that combines the two.\n",
    "\n",
    "## Tabular Encoder\n",
    "\n",
    "We now define an encoder architecture for tabular data that can be also used as a regressor when we set the number of output features to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0My5pxr4Cn8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RowEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 1024)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(1024, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iglfoZ04Cn8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now draw this encoder architecture for tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4ZS3LJH4Cn8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "row_encoder = RowEncoder(rows_train.shape[1], 1).double()\n",
    "sample = dataset_train[0]\n",
    "output = row_encoder(sample[\"row\"])\n",
    "make_dot(output, params=dict(list(row_encoder.named_parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NtBljZS4Cn9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This model has not been trained yet but we can already use it. Here is its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2wtnAw44Cn9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'output of the untrained model {output.item()}, true value is {sample[\"y\"].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVPQi9uz4Cn9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Following we define a training procedure to train the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R468XkqX4Cn-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "row_encoder = RowEncoder(rows_train.shape[1], 1).double()\n",
    "\n",
    "# batch size for the training loop\n",
    "batch_size = 10\n",
    "loader_train = DataLoader(dataset_train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "loader_val = DataLoader(dataset_val,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# define the optimizer and tell the optmize which parameter it should optmize\n",
    "optimizer = optim.Adam(row_encoder.parameters(), lr=0.00005)\n",
    "\n",
    "# used to visualize the losses\n",
    "plot_losses = PlotLosses(outputs=[MatplotlibPlot()])\n",
    "\n",
    "# early stopping configuration\n",
    "min_validation_loss = float('inf')\n",
    "max_patience = 20\n",
    "patience = max_patience\n",
    "\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    n_loss = 0\n",
    "    validation_loss = 0.0\n",
    "    for i, batch in enumerate(loader_train, 0):\n",
    "        # unpack the batch\n",
    "        rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "        # set the model in training mode\n",
    "        row_encoder.train()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward step\n",
    "        outputs = row_encoder(rows)\n",
    "        # compute the loss\n",
    "        loss = criterion(outputs, ys)\n",
    "        # backpropagation step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute losses and show them\n",
    "        running_loss += loss.item()\n",
    "        n_loss += len(batch)\n",
    "        if i % 5 == 4:\n",
    "            row_encoder.eval()\n",
    "            validation_loss = 0.0\n",
    "            for batch in loader_val:\n",
    "                rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "                outputs = row_encoder(rows)\n",
    "                validation_loss += criterion(outputs, ys).item()\n",
    "            plot_losses.update({'loss': running_loss / n_loss, 'val_loss': validation_loss / len(dataset_val)})\n",
    "            plot_losses.send()  # update plots\n",
    "            running_loss = 0.0\n",
    "            n_loss = 0\n",
    "\n",
    "    # early stopping checks\n",
    "    if validation_loss < min_validation_loss:\n",
    "        min_validation_loss = validation_loss\n",
    "        # save model or overwrite it if the validation loss has improved\n",
    "        torch.save(row_encoder.state_dict(), 'row_encoder_weights.pth')\n",
    "        patience = max_patience\n",
    "    else:\n",
    "        patience -= 1\n",
    "\n",
    "    if patience == 0:\n",
    "        print('Early stopping triggered at epoch', epoch)\n",
    "        break\n",
    "\n",
    "print(f'Training finished with best validation loss: {min_validation_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhUUr0oX4Cn-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now print the output of the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9spnGNJ4Cn-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'output of the untrained model {row_encoder(sample[\"row\"]).item()}, true value is {sample[\"y\"].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "641xqIhH4Cn-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Raster Encoder\n",
    "\n",
    "We now define an encoder architecture for raster data that can be also used as a regressor when we set the number of output features to 1. Note that while the previous was a Multi-Layer Perceptron based architecture, this will be a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BaU_Qtj4Cn_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_rasters, out_features=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=num_rasters,\n",
    "            out_channels=20,\n",
    "            kernel_size=3,\n",
    "            stride=1)\n",
    "        self.dropout2d1 = nn.Dropout2d(0.2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=20,\n",
    "            out_channels=10,\n",
    "            kernel_size=3,\n",
    "            stride=1)\n",
    "        self.dropout2d2 = nn.Dropout2d(0.2)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(490, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.conv1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout2d1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout2d2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jS1eDzMa4Cn_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now draw this encoder architecture for raster data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLePunDQ4Cn_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_encoder = ImageEncoder(sample['image'].shape[0], 1).double()\n",
    "sample = dataset_train[0]\n",
    "output = image_encoder(sample['image'].reshape(1, -1, 11, 11))\n",
    "make_dot(output, params=dict(list(image_encoder.named_parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1zO4rg44Cn_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now print the output of the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peSYyT5x4CoA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'output of the untrained model {output.item()}, true value is {sample[\"y\"].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TiZmCL_4CoA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We perform the sample training as done for the encoder for tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dpRJNqi4CoA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_encoder = ImageEncoder(sample['image'].shape[0], 1).double()\n",
    "\n",
    "batch_size = 10\n",
    "loader_train = DataLoader(dataset_train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "loader_val = DataLoader(dataset_val,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(image_encoder.parameters(), lr=0.00005)\n",
    "\n",
    "plot_losses = PlotLosses(outputs=[MatplotlibPlot()])\n",
    "\n",
    "min_validation_loss = float('inf')\n",
    "max_patience = 10\n",
    "patience = max_patience\n",
    "\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    n_loss = 0\n",
    "    for i, batch in enumerate(loader_train, 0):\n",
    "        rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "\n",
    "        image_encoder.train()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = image_encoder(images)\n",
    "        loss = criterion(outputs, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        n_loss += len(batch)\n",
    "        if i % 5 == 4:\n",
    "            image_encoder.eval()\n",
    "            validation_loss = 0.0\n",
    "            for batch in loader_val:\n",
    "                rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "                outputs = image_encoder(images)\n",
    "                validation_loss += criterion(outputs, ys).item()\n",
    "            plot_losses.update({'loss': running_loss / n_loss, 'val_loss': validation_loss / len(dataset_val)})\n",
    "            plot_losses.send()  # draw, update logs, etc\n",
    "            running_loss = 0.0\n",
    "            n_loss = 0\n",
    "\n",
    "    # early stopping strategy\n",
    "    if validation_loss < min_validation_loss:\n",
    "        min_validation_loss = validation_loss\n",
    "        torch.save(image_encoder.state_dict(), 'image_encoder_weights.pth')\n",
    "        patience = max_patience\n",
    "    else:\n",
    "        patience -= 1\n",
    "\n",
    "    if patience == 0:\n",
    "        print('Early stopping triggered at epoch', epoch)\n",
    "        break\n",
    "\n",
    "print(f'Training finished with best validation loss: {min_validation_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmnp_6Wk4CoA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now print the output of the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpbRYXvb4CoA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'output of the untrained model {image_encoder(sample[\"image\"].reshape(1, -1, 11, 11)).item()}, true value is {sample[\"y\"].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY3iXUp54CoA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Combine Architecture\n",
    "\n",
    "We now define a combine architecture that is able to handle tabular and raster data using the two encoders defined above. Note that we are using the encoders defined above using a number of output features larger than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3t5Swnxi4CoA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RowImageNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, num_rasters):\n",
    "        super().__init__()\n",
    "        # encoders with output features larger than 1, we call their output embeddings\n",
    "        self.row_encoder = RowEncoder(in_features, 20)\n",
    "        self.image_encoder = ImageEncoder(num_rasters, 20)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(40, 1)\n",
    "\n",
    "    def forward(self, x_row, x_image):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x_row = self.row_encoder(x_row)\n",
    "        x_image = self.image_encoder(x_image)\n",
    "        # concatenate the output of the two encoders\n",
    "        x = torch.cat((x_row, x_image), dim=1)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jc3zmUwM4CoB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now draw the combined architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51awPre_4CoB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "row_image_net = RowImageNet(rows_train.shape[1], dataset_train[0]['image'].shape[0]).double()\n",
    "sample = dataset_train[0]\n",
    "output = row_image_net(sample['row'].reshape(1, -1), sample['image'].reshape(1, -1, 11, 11))\n",
    "make_dot(output, params=dict(list(row_image_net.named_parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvONdsTq4CoB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This model has not been trained yet but we can already use it. Here is its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hurMEms14CoB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'output of the untrained model {output.item()}, true value is {sample[\"y\"].item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCLirPg-4CoB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "row_image_net = RowImageNet(rows_train.shape[1], sample['image'].shape[0]).double()\n",
    "\n",
    "batch_size = 10\n",
    "loader_train = DataLoader(dataset_train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "loader_val = DataLoader(dataset_val,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(row_image_net.parameters(), lr=0.00005)\n",
    "\n",
    "plot_losses = PlotLosses(outputs=[MatplotlibPlot()])\n",
    "\n",
    "min_validation_loss = float('inf')\n",
    "max_patience = 10\n",
    "patience = max_patience\n",
    "\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    n_loss = 0\n",
    "    validation_loss = 0.0\n",
    "    for i, batch in enumerate(loader_train, 0):\n",
    "        rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "\n",
    "        row_image_net.train()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward step\n",
    "        outputs = row_image_net(rows, images)\n",
    "        # compute the loss\n",
    "        loss = criterion(outputs, ys)\n",
    "        # backpropagation step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute losses and show them\n",
    "        running_loss += loss.item()\n",
    "        n_loss += len(batch)\n",
    "        if i % 5 == 4:\n",
    "            row_image_net.eval()\n",
    "            validation_loss = 0.0\n",
    "            for i, batch in enumerate(loader_val):\n",
    "                rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "                outputs = row_image_net(rows, images)\n",
    "                validation_loss += criterion(outputs, ys).item()\n",
    "\n",
    "            plot_losses.update({'loss': running_loss / n_loss, 'val_loss': validation_loss / len(dataset_val)})\n",
    "            plot_losses.send()  # draw, update logs, etc\n",
    "            running_loss = 0.0\n",
    "            n_loss = 0\n",
    "\n",
    "    # early stopping strategy\n",
    "    if validation_loss < min_validation_loss:\n",
    "        min_validation_loss = validation_loss\n",
    "        torch.save(row_image_net.state_dict(), 'row_image_net_weights.pth')\n",
    "        patience = max_patience\n",
    "    else:\n",
    "        patience -= 1\n",
    "\n",
    "    if patience == 0:\n",
    "        print('Early stopping triggered at epoch', epoch)\n",
    "        break\n",
    "\n",
    "print(f'Training finished with best validation loss: {min_validation_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPMjRb-M4CoB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'output of the untrained model {row_image_net(sample[\"row\"].reshape(1, -1), sample[\"image\"].reshape(1, -1, 11, 11)).item()}, true value is {sample[\"y\"].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwm9n9jJ4CoB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation and Comparison\n",
    "\n",
    "Now that we have trained the models above using their best hyper-parameters (manually), we can evaluate and compare the models using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg3fOxuW4CoB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "row_encoder = RowEncoder(rows_train.shape[1], 1).double()\n",
    "# load the weights of the best row encoder\n",
    "row_encoder.load_state_dict(torch.load('row_encoder_weights.pth'))\n",
    "row_encoder.eval()\n",
    "\n",
    "batch_size = 10\n",
    "loader_test = DataLoader(dataset_test,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)\n",
    "\n",
    "# collect the predictions\n",
    "pred_ys = []\n",
    "for i, batch in enumerate(loader_test, 0):\n",
    "    rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "    pred_ys.extend([x.item() for x in row_encoder(rows)])\n",
    "\n",
    "# compute the evaluation measures\n",
    "print(f'R2 {r2_score(ys_test, pred_ys)}')\n",
    "# back transform and compute the evaluation measures\n",
    "backtransformed_pred_ys = np.exp(min_max_scaler_ys.inverse_transform(np.array(pred_ys).reshape(-1, 1)))\n",
    "backtransformed_ys = np.exp(min_max_scaler_ys.inverse_transform(ys_test.reshape(1, -1)).reshape(-1))\n",
    "print(f'RMSE {np.sqrt(mean_squared_error(backtransformed_ys,backtransformed_pred_ys))}')\n",
    "\n",
    "plot.plot(ys_test, pred_ys, 'o')\n",
    "plot.axis('equal')\n",
    "plot.plot([-1, 1], [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO9evAlo4CoC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_encoder = ImageEncoder(sample['image'].shape[0], 1).double()\n",
    "# load the weights of the best row encoder\n",
    "row_encoder.load_state_dict(torch.load('row_encoder_weights.pth'))\n",
    "row_encoder.eval()\n",
    "\n",
    "batch_size = 10\n",
    "loader_test = DataLoader(dataset_test,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)\n",
    "\n",
    "# collect the predictions\n",
    "pred_ys = []\n",
    "for i, batch in enumerate(loader_test, 0):\n",
    "    rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "    pred_ys.extend([x.item() for x in image_encoder(images)])\n",
    "\n",
    "# compute the evaluation measures\n",
    "print(f'R2 {r2_score(ys_test, pred_ys)}')\n",
    "# back transform and compute the evaluation measures\n",
    "backtransformed_pred_ys = np.exp(min_max_scaler_ys.inverse_transform(np.array(pred_ys).reshape(-1, 1)))\n",
    "backtransformed_ys = np.exp(min_max_scaler_ys.inverse_transform(ys_test.reshape(1, -1)).reshape(-1))\n",
    "print(f'RMSE {np.sqrt(mean_squared_error(backtransformed_ys,backtransformed_pred_ys))}')\n",
    "\n",
    "plot.plot(ys_test, pred_ys, 'o')\n",
    "plot.axis('equal')\n",
    "plot.plot([-1, 1], [-1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvlXcsvJ4CoC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_encoder = ImageEncoder(sample['image'].shape[0], 1).double()\n",
    "# load the weights of the best row encoder\n",
    "row_image_net.load_state_dict(torch.load('row_image_net_weights.pth'))\n",
    "row_image_net.eval()\n",
    "\n",
    "batch_size = 10\n",
    "loader_test = DataLoader(dataset_test,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)\n",
    "\n",
    "\n",
    "# collect the predictions\n",
    "pred_ys = []\n",
    "for i, batch in enumerate(loader_test, 0):\n",
    "    rows, images, ys = batch['row'], batch['image'], batch['y']\n",
    "    pred_ys.extend([x.item() for x in row_image_net(rows, images)])\n",
    "\n",
    "# compute the evaluation measures\n",
    "print(f'R2 {r2_score(ys_test, pred_ys)}')\n",
    "# back transform and compute the evaluation measures\n",
    "backtransformed_pred_ys = np.exp(min_max_scaler_ys.inverse_transform(np.array(pred_ys).reshape(-1, 1)))\n",
    "backtransformed_ys = np.exp(min_max_scaler_ys.inverse_transform(ys_test.reshape(1, -1)).reshape(-1))\n",
    "print(f'RMSE {np.sqrt(mean_squared_error(backtransformed_ys,backtransformed_pred_ys))}')\n",
    "\n",
    "plot.plot(ys_test, pred_ys, 'o')\n",
    "plot.axis('equal')\n",
    "plot.plot([-1, 1], [-1, 1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
