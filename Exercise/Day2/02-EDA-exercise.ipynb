{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdanny/RSPW-23/blob/main/Exercise/Day2/02-EDA-exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am8wqV_R1nrs"
      },
      "source": [
        "# Day 2\n",
        "## Exploratory Data Analysis\n",
        "\n",
        "### Contents\n",
        "1. Numpy\n",
        "2. Pandas\n",
        "3. Matplotlib\n",
        "4. EDA\n",
        "\n",
        "### Aim\n",
        "At the end of this session, you will be able to:\n",
        "- Understand the basics of numpy.\n",
        "- Understand the basics of pandas.\n",
        "- Understand the basics of matplotlib.\n",
        "- Perform a simple EDA (Exploratory Data Analysis) using the libraries above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUs50zFo1nru"
      },
      "source": [
        "## EDA (Exploratory Data Analysis)\n",
        "To build and train machine learning models more efficiently, Exploratory Data Analysis, or EDA for short, should precede building the training model. This statistical approach was introduced by Professor John Tukey, also widely known for developing fast Fourier transform (FFT). \n",
        "The main goal of EDA is to analyze the data sets in order to understand their main characteristics, often with visualizations, summary tables and statistics. A thing to note is that visualization should be differentiated from EDA, as the former is mainly for the final stages of analysis and communication of results, while the latter is conducted at the beginning of the task.\n",
        "\n",
        "Remember the quote, \"Garbage In, Garbge Out!\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNKrlXRi1nru"
      },
      "source": [
        "The **basic order of EDA** theoretically is:\n",
        "   1. Find questions about the data set.\n",
        "   2. Find the answer to them on the data set using visualization, transformation and modelling.\n",
        "   3. Go deeper into the questions through the answers and find new questions.\n",
        "   4. Repeat tasks 1-3 iteratively until satisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TrbjFgT1nrv"
      },
      "source": [
        "### 1 Import Data and Libraries\n",
        "The dataset we use are from https://www.kaggle.com/c/nyc-taxi-trip-duration/data . \n",
        "\n",
        "The dataset is provided by Google Cloud Platform and is based on the 2016 NYC Yellow Cab trip record. Kaggle datasets are normally well-preprocessed, so practicing EDA with a Kaggle dataset can be a good start for beginners.\n",
        "\n",
        "The libraries that we covered so far (Numpy, Pandas, and Matplotlib) are your main tools for EDA. Additonally, `seaborn` is another famous library, used mainly for visualization.\n",
        "\n",
        "Because the size of the data is huge, we could only upload the dataset as zip file. Below cells unzips the zipped dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUltov7p1nrv"
      },
      "outputs": [],
      "source": [
        "# Check if you are running the notebook in colab or not\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pIH84GS1nrv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Downloading the dataset\n",
        "\n",
        "If you are running in Colab, run this cell to get the raw csv file from the web (GitHub)\n",
        "\"\"\"\n",
        "if IN_COLAB:\n",
        "    !wget https://raw.githubusercontent.com/kimdanny/RSPW-23/main/data/nyc-taxi-train.zip\n",
        "    !wget https://raw.githubusercontent.com/kimdanny/RSPW-23/main/data/nyc-taxi-test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVmQ1ORl1nrw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61Xox5w11nrw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGJLPxdl1nrw"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !unzip nyc-taxi-train.zip  \n",
        "    !unzip nyc-taxi-test.zip\n",
        "else:\n",
        "    # This follows the directory structure of RSPW-23 repository\n",
        "    !unzip ../../data/nyc-taxi-train.zip \n",
        "    !unzip ../../data/nyc-taxi-test.zip\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq5GTfgL1nrw"
      },
      "outputs": [],
      "source": [
        "# Let's see what the data is comprised of.\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRFUToAN1nrw"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgKLqmY31nrw"
      },
      "source": [
        "### 2. Check the Characteristics\n",
        "- `info()` : Gives brief information\n",
        "- `shape` : Returns data shape, (rows, columns)\n",
        "- `dtypes` : Returns data types of each columns\n",
        "- `describe()` : Returns the data statistics\n",
        "- `keys()` : Returns the the keys of columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yC4HuNg1nrx"
      },
      "outputs": [],
      "source": [
        "# To Do: Brief Information of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alaPCM0r1nrx"
      },
      "outputs": [],
      "source": [
        "# To Do: Return shape of our data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKHBSPyj1nrx"
      },
      "outputs": [],
      "source": [
        "# To Do: Return data types of each field (column name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "kcmVPJr31nrx"
      },
      "outputs": [],
      "source": [
        "# To Do: Return the data statistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTh6oKgx1nrx"
      },
      "source": [
        "### 3. Check the Values\n",
        "Checking for null values, anamolies and outliers in a dataset is an essential step in EDA before you actually apply ML on it.\n",
        "\n",
        "As this dataset is well-preprocess, you won't see any null values. However, do find out and learn how to deal with missing values or null values. We have discussed this in our pandas session. It is very normal to have corrupt data in the real world."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob1l-bha1nrx"
      },
      "outputs": [],
      "source": [
        "# Return the keys of the columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp1xg1Zq1nry"
      },
      "outputs": [],
      "source": [
        "# check if there's a null values in train dataset\n",
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbdexCMC1nry"
      },
      "outputs": [],
      "source": [
        "# minimum and maximum longitude in trainset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4bGrrEZ1nry"
      },
      "outputs": [],
      "source": [
        "# minimum and maximum latitude in trainset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8b4cTVL1nry"
      },
      "outputs": [],
      "source": [
        "# minimum and maximum longitude test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFofR1yu1nry"
      },
      "outputs": [],
      "source": [
        "# minimum and maximum latitude test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnQUl9y01nry"
      },
      "source": [
        "They are very similar, as we expected. Next, run the code below and get a histogram of all the pickup latitudes in the training set. Are you satisfied by what you see? What can you do to get a more informative representation of this data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfp66dGZ1nry"
      },
      "outputs": [],
      "source": [
        "plt.hist(train['pickup_latitude'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw-5ZJ2h1nrz"
      },
      "source": [
        "### Solution\n",
        "\n",
        "If we increase the number of bins and plot in a log-scale for the y-axis, we start to observe that there are outliers (the small bump above 37.5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ403_e21nrz"
      },
      "outputs": [],
      "source": [
        "# TODO: Increase the number of bins and plot in a log-scale for the y-axis, \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6uhZpTa1nrz"
      },
      "source": [
        "We can also focus in on regions of interest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtzB1yVt1nrz"
      },
      "outputs": [],
      "source": [
        "# We can also focus in on regions of interest\n",
        "# Create two plots of range (32.5, 40) and (40, 42.5)\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J75jLtKf1nrz"
      },
      "source": [
        "This gives us further understanding of the data, allowing us to decide how to handle the outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mk2tZlG1nrz"
      },
      "source": [
        "### 4. EDA Exercise\n",
        "\n",
        "Below, assign to X the first 100 trips that have `trip_duration<10000` and to Y - the first 100 trips that have `trip_duration>10000`. Run your code and observe the histogram. What conjecture can you make based on this data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txE_VANh1nr0"
      },
      "outputs": [],
      "source": [
        "# Define your X and Y code\n",
        "X = None\n",
        "Y = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEKhESds1nr0"
      },
      "outputs": [],
      "source": [
        "# Run the cell to see what it looks like\n",
        "bins = [1, 2, 3, 4, 5, 6]\n",
        "plt.hist(X['passenger_count'], bins, alpha=0.5)\n",
        "plt.hist(Y['passenger_count'], bins, alpha=0.5)\n",
        "plt.xlabel(\"Number of passengers\")\n",
        "plt.ylabel(\"Number of trips\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e-GfvVl1nr0"
      },
      "source": [
        "### 5. Making Derivative Attributes\n",
        "\n",
        "ML models digest only what we feed them. You cannot expect an ML model to know that the distance from the pickup spot to the dropoff spot is important. You have to make a new attribute for the distance and feed that into your model if you want it to take this into consideration.\n",
        "\n",
        "In general, if you come up with a new informative attribute that can possibly boost the model performance, consider adding it to your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU62tBTf1nr1"
      },
      "outputs": [],
      "source": [
        "# calculate the trip distance in miles\n",
        "# based on https://stackoverflow.com/questions/27928/\n",
        "# Returns distance in miles\n",
        "def distance(lat1, lon1, lat2, lon2):\n",
        "    p = 0.017453292519943295 # Pi/180\n",
        "    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
        "    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjAUfWaw1nr1"
      },
      "outputs": [],
      "source": [
        "train['distance'] = distance(None, None, None, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0I-Rp121nr1"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tIYTuW-1nr1"
      },
      "source": [
        "This is just the start of EDA. As mentioned above, having full insight on the data will help you build a stronger machine learning model. Find more materials and implement EDA yourself.\n",
        "\n",
        "### What do I do next?\n",
        "\n",
        "## MAKE YOUR OWN WONDERFUL EDA!\n",
        "\n",
        "### Challenge: Try to make a map using the logitude and latitude data from the taxicab data set above. Treating the logitude as X and the latitude as Y, draw a scatter plot and that should give you a good-looking map.\n",
        "\n",
        "The below websites should be helpful for your further study of EDA:\n",
        "- [Exploratory data analysis on Wikipedia](https://en.wikipedia.org/wiki/Exploratory_data_analysis)\n",
        "- [What is Exploratory Data Analysis?](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15)\n",
        "- [Introduction to Exploratory Data Analysis in Python](https://medium.com/python-pandemonium/introduction-to-exploratory-data-analysis-in-python-8b6bcb55c190)\n",
        "- [Kaggle: New York City Taxi trip duration notebooks](https://www.kaggle.com/c/nyc-taxi-trip-duration/notebooks)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2abcae20776490ba31080de71a1a7d4bc1f223b71e3c8ef1f9c424fbab927df1"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}